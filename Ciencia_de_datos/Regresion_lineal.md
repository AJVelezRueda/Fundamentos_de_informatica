>Este recorrido se basa en el material Joaqu√≠n Amat Rodrigo [Regresi√≥n lineal con Python](https://www.cienciadedatos.net/documentos/py10-regresion-lineal-python.html)

### Introducci√≥n a la Ciencia de Datos con Python

Para este recorrido necesitar√°s las librer√≠as [Pandas](https://pandas.pydata.org/), [Seaborn](https://seaborn.pydata.org/) y [Scipy](https://www.scipy.org/)


Podes corroborar si las tienes instaladas corriendo las siguientes l√≠neas en tu int√©rprete de Python:

```python
import pandas as pd
import seaborn as sns
import scipy.stats as ss
```

Si correr estas lineas no tira ning√∫n error, etonces est√°n felizmente instaladas las bibliotecas enc uesti√≥n. De lo contrario, obtendremos un mensaje de error `ModuleNotFoundError: No module named` al correr las lineas anteriores. En tal caso, pod√©s instalar las bibliotecas desde la consola, con el comando:

```bash
        pip install pandas
        pip install seaborn
        pip install scipy
```

# Guias de Trabajo
 * [1. De relaciones, etiquetas y otras yerbas](#1_intro)
 * [2. Regresi√≥n lineal](#2_regresion)
 * [3. Ajuste del modelo](#3_ajuste)
 * [4. Manos a los datos](#4_ejemplo)


[1. De relaciones, etiquetas y otras yerbas](#1_intro)

Hemos estado trabajando en [clustering o agrupamientos](https://github.com/AJVelezRueda/Fundamentos_de_informatica/blob/master/Ciencia_de_datos/Clustering.md), donde intentamos encontrar patrones en datos cont√≠nuos sin etiquetas. Como ya hemos visto, estos m√©todos nos permiten encontrar similitudes entre las observaciones de modo que podamos agruparlas seg√∫n caracter√≠sticas en com√∫n y diferenciarlas de los otros grupos de observaciones. 

La clusterizaci√≥n es lo que denominamos un m√©tdo de aprendizaje **no supervisado**; donde solo disponemos de un conjunto de datos no etiquetados de entrada, sobre los que debemos obtener informaci√≥n, sin conocer previamente cu√°l ser√° la salida. 

Existen t√©cnicas que nos permiten trabajar con datos etiquetados. Los algoritmos de **aprendizaje supervisado**, se utilizan para hacer predicciones. Existen dos tipos de algoritmos de predicci√≥n: los algoritmos de regresi√≥n y los de clasificaci√≥n, cuya principal diferencia radica en que los algoritmos de regresi√≥n se utilizan para hacer predecciones sobre valores continuos, mientras que los algoritmos de clasificaci√≥n se utilizan para predecir/clasificar los valores discretos.

Podemos resumir algunas de las diferencias m√°s importantes entre estos algoritmos del siguiente modo:


| Regresi√≥n | Clasificaci√≥n | 
|-------------	|----------	|
| la variable de salida debe ser de naturaleza continua o valor real |  la variable de salida debe ser un valor discreto | 
| La tarea del algoritmo de regresi√≥n es mapear el valor de entrada (x) con la variable de salida continua (y)| La tarea del algoritmo de clasificaci√≥n es mapear el valor de entrada (x) con la variable de salida discreta (y) |
|   Un problema de regresi√≥n necesita la predicci√≥n de una cantidad | En un problema de clasificaci√≥n, los datos se etiquetan en una de dos o m√°s clases |
| En Regresi√≥n, intentamos encontrar la l√≠nea de mejor ajuste, que puede predecir la salida con mayor precisi√≥n |En Clasificaci√≥n, intentamos encontrar el l√≠mite de decisi√≥n, que puede dividir el conjunto de datos en diferentes clases |

Seg√∫n el problema a resolver y las caracter√≠stica de nuestros datos seleccionaremos el m√©todo m√°s apropiado para su resoluci√≥n.

[2. Regresi√≥n lineal](#2_regresion)

En este recorrido nos enfocaremos en predecir o estudiar las relaciones entre las variables. En particular, en un tipo de relaci√≥n: lineal. Este m√©todo estad√≠stico se usa para describir una variable continua como una funci√≥n de una o varias variables independientes. 

Las t√©cnicas de regresi√≥n lineal tratan de modelar la relaci√≥n entre una variable continua y una o m√°s variables independientes mediante el ajuste de una ecuaci√≥n lineal.

Si bien, nuestra suposici√≥n basal es que muestros datos debr√≠an caer sobre una recta que describe la relaci√≥n entre nuestras variables, las observaciones no cumplen con esta idealidad. Cada valor se aparta de la "recta ideal" en un valor de error (œµ). De ah√≠ que la ecuaci√≥n general correspondiente a un modelo de regresi√≥n lineal es:

``
Yi = Œ≤0 + ‚àë Œ≤i.Xi + œµi
``

Donde Œ≤0 se corresponde con la ordenada al origen (es decir, el valor de y cuando las dem√°s variables son cero) y Œ≤i es el efecto promedio que tiene el cambio en Xi sobre la variable Y (cuando el resto de las variables es constante). Esto representa la pendiente de la recta.


[3. Ajuste del modelo](#3_ajuste)

Ajustar el modelo consiste en estimar, a partir de los datos disponibles:
- la recta que minimice la distancia entre mis datos y esta 
- encontrar los valores de los coeficientes de regresi√≥n que maximizan la probabilidad de que la recta prediga los valores observados.

El m√©todo  m√°s utilizado para el ajuste del modelo lineal es el de m√≠nimos cuadrados, que identifica como mejor modelo la recta (o plano si es regresi√≥n m√∫ltiple) que minimiza la suma de los cuadrados de los errores:

```python
œµ2  = ‚àë (yi - ≈∑i)2 
```

Es  decir,  la  suma  de  los  cuadrados  de  las  diferencias  entre  los  valores  reales  observados  (yi)  y los valores estimados (≈∑i)

![Ajuste de m√≠nimos cuadrados](./regresion.jpeg)

Como se ve en el gr√°fico, la l√≠nea gris representa la recta de regresi√≥n (el modelo) y los segmentos rojos el error entre esta y cada observaci√≥n.

[4. Manos a los datos](#4_ejemplo)

Tomemos un ejemplo concreto. Supongamos que un analista de deportes quiere saber si existe una relaci√≥n entre el n√∫mero de veces que batean los jugadores de un equipo de b√©isbol y el n√∫mero de runs que consigue; y en caso de existir, establecer un modelo que le permita predecir el resultado de partidos futuros:

```python
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

equipos = ["Texas","Boston","Detroit","Kansas","St.","New_S.","New_Y.",
           "Milwaukee","Colorado","Houston","Baltimore","Los_An.","Chicago",
           "Cincinnati","Los_P.","Philadelphia","Chicago","Cleveland","Arizona",
           "Toronto","Minnesota","Florida","Pittsburgh","Oakland","Tampa",
           "Atlanta","Washington","San.F","San.I","Seattle"]
bateos = [5659,  5710, 5563, 5672, 5532, 5600, 5518, 5447, 5544, 5598,
          5585, 5436, 5549, 5612, 5513, 5579, 5502, 5509, 5421, 5559,
          5487, 5508, 5421, 5452, 5436, 5528, 5441, 5486, 5417, 5421]

runs = [855, 875, 787, 730, 762, 718, 867, 721, 735, 615, 708, 644, 654, 735,
        667, 713, 654, 704, 731, 743, 619, 625, 610, 645, 707, 641, 624, 570,
        593, 556]

datos = {'equipos': equipos, 'bateos': bateos, 'runs': runs}
```

> üßó‚Äç‚ôÄÔ∏è Desaf√≠o I: dado el diccionario con los datos de partidos anteriores crea un DataFrame de nombre `datos_partidos_previos`
>
> üßó‚Äç‚ôÄÔ∏è Desaf√≠o II: grafic√° el n√∫mero de bateos vs el numero de runs, para observar la relaci√≥n entre ambas variables 
> Para pensar ü§î: ¬øObservas una tendencia en los datos?
>

<details>
  <summary>Pista</summary>
 sns.scatterplot(data=tips, x="bateos", y="runs")
</details>

Ahora veamos de forma num√©rica si existe la misma tendencia que se observa gr√°ficamente:

```python
from scipy.stats import pearsonr

corr_test = pearsonr(x = datos['bateos'], y =  datos['runs'])
print("Coeficiente de correlaci√≥n de Pearson: ", corr_test[0])
print("P-value: ", corr_test[1])
```

Coeficiente de correlaci√≥n de Pearson es un √≠ndice que mide el grado de covariaci√≥n entre dos variables. M√°s formalmente describe la proporci√≥n de varianza de y explicada por el modelo y relativa a la varianza total. Su valor est√° acotado entre 0 y 1.

> Para pensar ü§î: ¬øQu√© nos dice el coeficiente de correlaci√≥n de Pearson (R2)obtenido para nuestro ejemplo? ¬øy el valor P? ¬øTiene sentido intentar generar un modelo de regresi√≥n lineal?
>

Como en todo estudio predictivo, no solo es importante ajustar el modelo, sino tambi√©n cuantificar su capacidad para predecir nuevas observaciones. Para poder hacer esta evaluaci√≥n, se dividen los datos en dos grupos, uno de entrenamiento y otro de test.

```python
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X = datos[['bateos']]
y = datos['runs']

X_train, X_test, y_train, y_test = train_test_split(
                                        X.values.reshape(-1,1),
                                        y.values.reshape(-1,1),
                                        train_size   = 0.8,
                                        random_state = 1234,
                                        shuffle      = True
                                    )

modelo = LinearRegression()
modelo.fit(X = X_train.reshape(-1, 1), y = y_train)
```

Podemos imprimir los valores de ordenada al origen (intercept_) y toda la informaci√≥n de nuestro modelo haciendo:

```python
print("Intercept:", modelo.intercept_)
print("Coeficiente:", list(zip(X.columns, modelo.coef_.flatten(), )))
print("Coeficiente de determinaci√≥n R^2:", modelo.score(X, y))
```
Ahora, una vez entrenado el modelo, podemos evaluar la capacidad predictiva usando el conjunto de test:

```python
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

predicciones = modelo.predict(X = X_test)
print(predicciones[0:3,])

```

¬øPero c√≥mo podemos saber si las predicciones son buenas o malas? Pues podemos calcular el error, teniendo en cuenta el valor predicho y respecto de un valor observado o conocido. El error cuadr√°tico medio (RMSE) mide la cantidad de error que hay entre dos conjuntos de datos:

```python
from sklearn.metrics import mean_squared_error
rmse = mean_squared_error(
        y_true  = y_test,
        y_pred  = predicciones,
        squared = False
       )

print(f"El error (rmse) de test es: {rmse}")
```

El RMSE tiene la misma unidad que la variable dependiente, lo que significa que no hay un umbral absoluto bueno o malo, aunque puede ser definido en funci√≥n de su variable dependiente. Para entender mejor el resultado que obtuvimos veamos dos ejemplos:

- Ejemplo 1: Nos gustar√≠a utilizar un modelo de regresi√≥n para predecir el precio de las viviendas en una ciudad dada. Suponga que el modelo que obtuvimos tiene un valor RMSE de $ 500. Dado que el rango t√≠pico de precios de las casas est√° entre $ 70.000 y $ 300.000, este valor de RMSE es extremadamente bajo. Lo cual, nos dice que el modelo puede predecir con precisi√≥n los precios de la vivienda.

- Ejemplo 2: ahora supongamos que nos gustar√≠a usar un modelo de regresi√≥n para predecir cu√°nto gastar√° alguien por mes en su estad√≠a en una ciudad determinada. Suponga que el modelo tiene un valor RMSE de $ 500. Dado un rango t√≠pico de gasto mensual de entre $ 1500 a $ 4000, este valor de RMSE es bastante alto, por lo que el modelo no puede predecir el gasto mensual con mucha precisi√≥n.



> Para pensar ü§î: A la luz de lo aprendido ¬øCu√°n bueno es el poder predictivo de nuestro modelo?
>

Podemos llevar esta observaci√≥n a valores concretos, mediante la normalizaci√≥n del RMSE:

RMSE_normalizado = RMSE / (valor m√°ximo - valor m√≠nimo)

De este modo podremos obgener valores entre 0 y 1, donde los valores m√°s cercanos a 0 representan modelos de mejor ajuste.

> üßó‚Äç‚ôÄÔ∏è Desaf√≠o II: Calcul√° el valor normalizado el RMSE
>
> Para pensar ü§î: ¬øSe corresponden tus suposiciones con lo obtenido num√©ricamente?
>