>Este recorrido se basa en el material JoaquÃ­n Amat Rodrigo [RegresiÃ³n lineal con Python](https://www.cienciadedatos.net/documentos/py10-regresion-lineal-python.html)

### IntroducciÃ³n a la Ciencia de Datos con Python

Para este recorrido necesitarÃ¡s las librerÃ­as [Pandas](https://pandas.pydata.org/), [Seaborn](https://seaborn.pydata.org/) y [Scipy](https://www.scipy.org/)


Podes corroborar si las tienes instaladas corriendo las siguientes lÃ­neas en tu intÃ©rprete de Python:

```python
import pandas as pd
import seaborn as sns
import scipy.stats as ss
```

Si correr estas lineas no tira ningÃºn error, etonces estÃ¡n felizmente instaladas las bibliotecas enc uestiÃ³n. De lo contrario, obtendremos un mensaje de error `ModuleNotFoundError: No module named` al correr las lineas anteriores. En tal caso, podÃ©s instalar las bibliotecas desde la consola, con el comando:

```bash
        pip install pandas
        pip install seaborn
        pip install scipy
```

# Guias de Trabajo
 * [1. De relaciones, etiquetas y otras yerbas](#1_intro)
 * [2. RegresiÃ³n lineal](#2_regresion)
 * [3. Ajuste del modelo](#3_ajuste)
 * [4. Manos a los datos](#4_ejemplo)


[1. De relaciones, etiquetas y otras yerbas](#1_intro)

Hemos estado trabajando en [clustering o agrupamientos](https://github.com/AJVelezRueda/Fundamentos_de_informatica/blob/master/Ciencia_de_datos/Clustering.md), donde intentamos encontrar patrones en datos contÃ­nuos sin etiquetas. Como ya hemos visto, estos mÃ©todos nos permiten encontrar similitudes entre las observaciones de modo que podamos agruparlas segÃºn caracterÃ­sticas en comÃºn y diferenciarlas de los otros grupos de observaciones. 

La clusterizaciÃ³n es lo que denominamos un mÃ©tdo de aprendizaje **no supervisado**; donde solo disponemos de un conjunto de datos no etiquetados de entrada, sobre los que debemos obtener informaciÃ³n, sin conocer previamente cuÃ¡l serÃ¡ la salida. 

Existen tÃ©cnicas que nos permiten trabajar con datos etiquetados. Los algoritmos de **aprendizaje supervisado**, se utilizan para hacer predicciones. Existen dos tipos de algoritmos de predicciÃ³n: los algoritmos de regresiÃ³n y los de clasificaciÃ³n, cuya principal diferencia radica en que los algoritmos de regresiÃ³n se utilizan para hacer predecciones sobre valores continuos, mientras que los algoritmos de clasificaciÃ³n se utilizan para predecir/clasificar los valores discretos.

Podemos resumir algunas de las diferencias mÃ¡s importantes entre estos algoritmos del siguiente modo:


| RegresiÃ³n | ClasificaciÃ³n | 
|-------------	|----------	|
| la variable de salida debe ser de naturaleza continua o valor real |  la variable de salida debe ser un valor discreto | 
| La tarea del algoritmo de regresiÃ³n es mapear el valor de entrada (x) con la variable de salida continua (y)| La tarea del algoritmo de clasificaciÃ³n es mapear el valor de entrada (x) con la variable de salida discreta (y) |
|   Un problema de regresiÃ³n necesita la predicciÃ³n de una cantidad | En un problema de clasificaciÃ³n, los datos se etiquetan en una de dos o mÃ¡s clases |
| En RegresiÃ³n, intentamos encontrar la lÃ­nea de mejor ajuste, que puede predecir la salida con mayor precisiÃ³n |En ClasificaciÃ³n, intentamos encontrar el lÃ­mite de decisiÃ³n, que puede dividir el conjunto de datos en diferentes clases |

SegÃºn el problema a resolver y las caracterÃ­stica de nuestros datos seleccionaremos el mÃ©todo mÃ¡s apropiado para su resoluciÃ³n.

[2. RegresiÃ³n lineal](#2_regresion)

En este recorrido nos enfocaremos en predecir o estudiar las relaciones entre las variables. En particular, en un tipo de relaciÃ³n: lineal. Este mÃ©todo estadÃ­stico se usa para describir una variable continua como una funciÃ³n de una o varias variables independientes. 

Las tÃ©cnicas de regresiÃ³n lineal tratan de modelar la relaciÃ³n entre una variable continua y una o mÃ¡s variables independientes mediante el ajuste de una ecuaciÃ³n lineal.

Si bien, nuestra suposiciÃ³n basal es que muestros datos debrÃ­an caer sobre una recta que describe la relaciÃ³n entre nuestras variables, las observaciones no cumplen con esta idealidad. Cada valor se aparta de la "recta ideal" en un valor de error (Ïµ). De ahÃ­ que la ecuaciÃ³n general correspondiente a un modelo de regresiÃ³n lineal es:

``
Yi = Î²0 + âˆ‘ Î²i.Xi + Ïµi
``

Donde Î²0 se corresponde con la ordenada al origen (es decir, el valor de y cuando las demÃ¡s variables son cero) y Î²i es el efecto promedio que tiene el cambio en Xi sobre la variable Y (cuando el resto de las variables es constante). Esto representa la pendiente de la recta.


[3. Ajuste del modelo](#3_ajuste)

Ajustar el modelo consiste en estimar, a partir de los datos disponibles:
- la recta que minimice la distancia entre mis datos y esta 
- encontrar los valores de los coeficientes de regresiÃ³n que maximizan la probabilidad de que la recta prediga los valores observados.

El mÃ©todo  mÃ¡s utilizado para el ajuste del modelo lineal es el de mÃ­nimos cuadrados, que identifica como mejor modelo la recta (o plano si es regresiÃ³n mÃºltiple) que minimiza la suma de los cuadrados de los errores:

```python
Ïµ2  = âˆ‘ (yi - Å·i)2 
```

Es  decir,  la  suma  de  los  cuadrados  de  las  diferencias  entre  los  valores  reales  observados  (yi)  y los valores estimados (Å·i)

![Ajuste de mÃ­nimos cuadrados](./regresion.jpeg)

Como se ve en el grÃ¡fico, la lÃ­nea gris representa la recta de regresiÃ³n (el modelo) y los segmentos rojos el error entre esta y cada observaciÃ³n.

[4. Manos a los datos](#4_ejemplo)

Tomemos un ejemplo concreto. Supongamos que un analista de deportes quiere saber si existe una relaciÃ³n entre el nÃºmero de veces que batean los jugadores de un equipo de bÃ©isbol y el nÃºmero de runs que consigue; y en caso de existir, establecer un modelo que le permita predecir el resultado de partidos futuros:

```python
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

equipos = ["Texas","Boston","Detroit","Kansas","St.","New_S.","New_Y.",
           "Milwaukee","Colorado","Houston","Baltimore","Los_An.","Chicago",
           "Cincinnati","Los_P.","Philadelphia","Chicago","Cleveland","Arizona",
           "Toronto","Minnesota","Florida","Pittsburgh","Oakland","Tampa",
           "Atlanta","Washington","San.F","San.I","Seattle"]
bateos = [5659,  5710, 5563, 5672, 5532, 5600, 5518, 5447, 5544, 5598,
          5585, 5436, 5549, 5612, 5513, 5579, 5502, 5509, 5421, 5559,
          5487, 5508, 5421, 5452, 5436, 5528, 5441, 5486, 5417, 5421]

runs = [855, 875, 787, 730, 762, 718, 867, 721, 735, 615, 708, 644, 654, 735,
        667, 713, 654, 704, 731, 743, 619, 625, 610, 645, 707, 641, 624, 570,
        593, 556]

datos = {'equipos': equipos, 'bateos': bateos, 'runs': runs}
```

> ðŸ§—â€â™€ï¸ DesafÃ­o I: dado el diccionario con los datos de partidos anteriores crea un DataFrame de nombre `datos_partidos_previos`
>
> ðŸ§—â€â™€ï¸ DesafÃ­o II: graficÃ¡ el nÃºmero de bateos vs el numero de runs, para observar la relaciÃ³n entre ambas variables 
> Para pensar ðŸ¤”: Â¿Observas una tendencia en los datos?
>

<details>
  <summary>Pista</summary>
 sns.scatterplot(data=tips, x="bateos", y="runs")
</details>

Ahora veamos de forma numÃ©rica si existe la misma tendencia que se observa grÃ¡ficamente:

```python
from scipy.stats import pearsonr

corr_test = pearsonr(x = datos['bateos'], y =  datos['runs'])
print("Coeficiente de correlaciÃ³n de Pearson: ", corr_test[0])
print("P-value: ", corr_test[1])
```

Coeficiente de correlaciÃ³n de Pearson es un Ã­ndice que mide el grado de covariaciÃ³n entre dos variables. MÃ¡s formalmente describe la proporciÃ³n de varianza de y explicada por el modelo y relativa a la varianza total. Su valor estÃ¡ acotado entre 0 y 1.

> Para pensar ðŸ¤”: Â¿QuÃ© nos dice el coeficiente de correlaciÃ³n de Pearson (R2)obtenido para nuestro ejemplo? Â¿y el valor P? Â¿Tiene sentido intentar generar un modelo de regresiÃ³n lineal?
>

Como en todo estudio predictivo, no solo es importante ajustar el modelo, sino tambiÃ©n cuantificar su capacidad para predecir nuevas observaciones. Para poder hacer esta evaluaciÃ³n, se dividen los datos en dos grupos, uno de entrenamiento y otro de test.

```python
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

X = datos[['bateos']]
y = datos['runs']

X_train, X_test, y_train, y_test = train_test_split(
                                        X.values.reshape(-1,1),
                                        y.values.reshape(-1,1),
                                        train_size   = 0.8,
                                        random_state = 1234,
                                        shuffle      = True
                                    )

modelo = LinearRegression()
modelo.fit(X = X_train.reshape(-1, 1), y = y_train)
```

Podemos imprimir los valores de ordenada al origen (intercept_) y toda la informaciÃ³n de nuestro modelo haciendo:

```python
print("Intercept:", modelo.intercept_)
print("Coeficiente:", list(zip(X.columns, modelo.coef_.flatten(), )))
print("Coeficiente de determinaciÃ³n R^2:", modelo.score(X, y))
```
Ahora, una vez entrenado el modelo, podemos evaluar la capacidad predictiva usando el conjunto de test:

```python
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

predicciones = modelo.predict(X = X_test)
print(predicciones[0:3,])

```

Â¿Pero cÃ³mo podemos saber si las predicciones son buenas o malas? Pues podemos calcular el error, teniendo en cuenta el valor predicho y respecto de un valor observado o conocido. El error cuadrÃ¡tico medio (RMSE) mide la cantidad de error que hay entre dos conjuntos de datos:

```python
from sklearn.metrics import mean_squared_error
rmse = mean_squared_error(
        y_true  = y_test,
        y_pred  = predicciones,
        squared = False
       )

print(f"El error (rmse) de test es: {rmse}")
```

El RMSE tiene la misma unidad que la variable dependiente, lo que significa que no hay un umbral absoluto bueno o malo, aunque puede ser definido en funciÃ³n de su variable dependiente. Para entender mejor el resultado que obtuvimos veamos dos ejemplos:

- Ejemplo 1: Nos gustarÃ­a utilizar un modelo de regresiÃ³n para predecir el precio de las viviendas en una ciudad dada. Suponga que el modelo que obtuvimos tiene un valor RMSE de $ 500. Dado que el rango tÃ­pico de precios de las casas estÃ¡ entre $ 70.000 y $ 300.000, este valor de RMSE es extremadamente bajo. Lo cual, nos dice que el modelo puede predecir con precisiÃ³n los precios de la vivienda.

- Ejemplo 2: ahora supongamos que nos gustarÃ­a usar un modelo de regresiÃ³n para predecir cuÃ¡nto gastarÃ¡ alguien por mes en su estadÃ­a en una ciudad determinada. Suponga que el modelo tiene un valor RMSE de $ 500. Dado un rango tÃ­pico de gasto mensual de entre $ 1500 a $ 4000, este valor de RMSE es bastante alto, por lo que el modelo no puede predecir el gasto mensual con mucha precisiÃ³n.



> Para pensar ðŸ¤”: A la luz de lo aprendido Â¿CuÃ¡n bueno es el poder predictivo de nuestro modelo?
>

Podemos llevar esta observaciÃ³n a valores concretos, mediante la normalizaciÃ³n del RMSE:

RMSE_normalizado = RMSE / (valor mÃ¡ximo - valor mÃ­nimo)

De este modo podremos obgener valores entre 0 y 1, donde los valores mÃ¡s cercanos a 0 representan modelos de mejor ajuste.

> ðŸ§—â€â™€ï¸ DesafÃ­o II: CalculÃ¡ el valor normalizado el RMSE
>
> Para pensar ðŸ¤”: Â¿Se corresponden tus suposiciones con lo obtenido numÃ©ricamente?
>