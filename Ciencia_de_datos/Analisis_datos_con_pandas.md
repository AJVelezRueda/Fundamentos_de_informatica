# Introducci√≥n a la Ciencia de Datos con Python

üö® Este material fue creado por Ana Julia Velez Rueda y como todo el repositorio se encuentra bajo licencia 
[Creative Commons Attribution-ShareAlike 4.0 International License][cc-by-sa].

[![CC BY-SA 4.0][cc-by-sa-image]][cc-by-sa]

[cc-by-sa]: http://creativecommons.org/licenses/by-sa/4.0/
[cc-by-sa-image]: https://licensebuttons.net/l/by-sa/4.0/88x31.png
[cc-by-sa-shield]: https://img.shields.io/badge/License-CC%20BY--SA%204.0-lightgrey.svg


> Este material retoma material de [Recursos Python](https://github.com/flbulgarelli/recursos-python/blob/master/2_Ciencia_de_datos_pandas/Analisis_de_datos_con_pandas.md)


<details>
  <summary>üö® REQUERIMIENTOS</summary>


Para este recorrido necesitar√°s las librer√≠as [Pandas](https://pandas.pydata.org/), [Seaborn](https://seaborn.pydata.org/) y [Scipy](https://www.scipy.org/)


Podes corroborar si las tienes instaladas corriendo las siguientes l√≠neas en tu int√©rprete de Python:

```python
import pandas as pd
import seaborn as sns
import scipy.stats as ss
```

Si correr estas lineas no tira ning√∫n error, etonces est√°n felizmente instaladas las bibliotecas enc uesti√≥n. De lo contrario, obtendremos un mensaje de error `ModuleNotFoundError: No module named` al correr las lineas anteriores. En tal caso, pod√©s instalar las bibliotecas desde la consola, con el comando:

```bash
        pip install pandas
        pip install seaborn
        pip install scipy
```

En este recorrido trabajaremos sobre los datos abiertos del sobre el personal del [Ministerio de Ciencia y Tecnolog√≠a](https://datasets.datos.mincyt.gob.ar/dataset/personal-de-ciencia-y-tecnologia/archivo/11dca5bb-9a5f-4da5-b040-28957126be18) del Gobierno Argentino. 

Si bien no es estrictamente necesario saber a fondo la sintaxis de Python para comenzar a utilizar Pandas, te recomendamos fuertemente realizar el [recorrido introductorio de Python](https://github.com/AJVelezRueda/UCEMA_Fundamentos_de_informatica/blob/master/Python_intro/intro_python_tutorial.md), que te brindar√° los conocimientos b√°sicos de programaci√≥n en general y de Python particular que te permitiran abordar este contenido sin problemas.

</details>

## Guias de Trabajo
 * [1. Carga e inspecci√≥n de datos](#1-carga)
 * [2. Tratamiento de datos faltantes](#2-faltantes)
 * [3. Tratamiento de tipos de datos de las columnas](#3-tipos_datos)


[1. Tratamiento de Datos con Python](#1-carga)

El primer paso para poder analizar los datos y sacar conclusiones de ese an√°lisis es realizar una
limpieza de los mismos... ¬°claro que no vamos a pasarle el plumero para sacarle el polvo! Limpieza de datos se refiere por ejemplo a verificar si faltan datos o si a alguna de las columnas debe hacerseles una correcci√≥n de notaci√≥n o de tipo de dato, etc.

Para ello vamos a recurrir a alguno de los m√©todos que vimos en la [gu√≠a introductoria](https://github.com/flbulgarelli/recursos-python/blob/master/2_Ciencia_de_datos_pandas/Introducci%C3%B3n_pandas.md). Para comenzar descargaremos localmente la [tabla](https://datasets.datos.mincyt.gob.ar/dataset/personal-de-ciencia-y-tecnologia/archivo/11dca5bb-9a5f-4da5-b040-28957126be18) de personas que conforman el Ministerio de Ciencia y Tecnolog√≠a de Argentina, en formato csv. Podemos cargar (leer) la el contenido del archivo en un DataFrame de Pandas de nombre `personas`

```python
import pandas as pd
personas =  pd.read_csv("personas_2011_cyt.csv", sep=";")
personas.head()
```

> Para pensar ü§î: Al imprimir el DataFrame se ven celdas con valores `NaN` ¬øQu√© son esos valores?¬øQu√© significa? ¬øA qu√© columna corresponden estos valores? ¬øQu√© tipo de datos son los pertenecientas a cada una de las columnas (categ√≥ricos o num√©ricos)?

Podemos obtener la informaci√≥n general del DataFrame haciendo:


```python
personas.info()
```

<details>
  <summary>Resultado</summary>

```python
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 68552 entries, 0 to 68551
Data columns (total 21 columns):
 #   Column                                Non-Null Count  Dtype  
---  ------                                --------------  -----  
 0   persona_id                            68552 non-null  int64  
 1   anio                                  68552 non-null  int64  
 2   sexo_id                               68552 non-null  int64  
 3   edad                                  68552 non-null  int64  
 4   maximo_grado_academico_id             68552 non-null  int64  
 5   disciplina_maximo_grado_academico_id  68552 non-null  int64  
 6   disciplina_titulo_grado_id            68552 non-null  int64  
 7   disciplina_experticia_id              68552 non-null  int64  
 8   tipo_personal_id                      68552 non-null  int64  
 9   producciones_ult_anio                 68552 non-null  int64  
 10  producciones_ult_2_anios              68552 non-null  int64  
 11  producciones_ult_3_anios              68552 non-null  int64  
 12  producciones_ult_4_anios              68552 non-null  int64  
 13  institucion_trabajo_id                68552 non-null  int64  
 14  seniority_level                       68552 non-null  object 
 15  categoria_conicet_id                  48640 non-null  float64
 16  categoria_incentivos                  48640 non-null  float64
 17  max_dedicacion_horaria_docente_id     48640 non-null  float64
 18  institucion_cargo_docente_id          48640 non-null  float64
 19  clase_cargo_docente_id                48640 non-null  float64
 20  tipo_condicion_docente_id             48640 non-null  float64
dtypes: float64(6), int64(14), object(1)
memory usage: 11.0+ MB
```
</details>

Como ver√°s esta es una descripci√≥n gen√©rica de nuestro DataFrame, de la cu√°l podemos obtener el nombre de cada columna (variable), el tipo de datos correspondiente a cada una de ellas, y cu√°ntas filas por columna poseen informaci√≥n.

Sin embargo, el an√°lisis de los datos implica hacernos preguntas sobre la informaci√≥n que estos contienen e intentar encontrar respuestas, dentro de lo posible que sean generalizables. Aqu√≠ es donde entra en juego ü•Å...¬°Si: La estad√≠stica!

Podemos hacer un primer an√°lisis estad√≠stico b√°sico de nuestro conjunto de datos utilizando el m√©todo `describe()`:

```python
personas.describe()
```

> Para pensar ü§î: ¬øQu√© datos nos devuelve el m√©todo `describe()`? ¬øQu√© significan estos valores?¬øSon √∫tiles para todas las columnas?

De la inspecci√≥n general de los datos y su an√°lisis estad√≠stico b√°sico podemos decir, por ejemplo, que el promedio de edades es de 38 a√±os ¬øPero podemos decir que el promedio de maximo_grado_academico_id es 3? Bueno, es claro que el m√°ximo grado acad√©mico habla de cual es el nivel m√°s alto de estudios que logr√≥ cada persona (primario, secundario, universitario, etc) por lo que 3 no tiene ning√∫n sentido en este caso. Pero a√∫n reemplazando las palabras correspondientes a cada identificador, un promedio no tiene sentido alguno para esta variable. 

Sin embargo, nos puede interesar saber cu√°l es el grado de formaci√≥n que tiene el personal ¬øSon mayormente universitarixs? ¬ømayormente terminaron el secundario? Para ello podemos calcular la frecuencia de aparici√≥n de cada una de estas categor√≠as/datos. Esto es contar cu√°ntas veces del total de filas aparece cada una de ellas:

```python
personas['maximo_grado_academico_id'].value_counts()
```

>üßó‚Äç‚ôÄÔ∏è Desaf√≠o I: Tomando las [tablas de referencia del MinCyT](https://datasets.datos.mincyt.gob.ar/dataset/personal-de-ciencia-y-tecnologia/archivo/11dca5bb-9a5f-4da5-b040-28957126be18) y tomando lo aprendido en el [recorrido anterior](https://github.com/flbulgarelli/recursos-python/blob/master/2_Ciencia_de_datos_pandas/Introducci%C3%B3n_pandas.md), incorpor√° los datos correspondientes a todas las variables categ√≥ricas de la tabla

[2. Tratamiento de datos faltantes](#2-faltantes)
No hace falta suspicacia para prever que en esta secci√≥n hablaremos de los datos faltantes. Obtivimos anteriormente, con el m√©todo `info()`, cu√°ntos valores no nulos posee cada columna. 

Ahora nos vamos a enfocar en el vaso medio vac√≠o, vamos a intentar cuantificar cu√°ntas celdas hayen nuetsra tabla sin informaci√≥n. Probemos el siguiente c√≥digo:

```python
personas.isnull().sum()
```

<details>
  <summary>Resultado</summary>

```python
persona_id                                  0
anio                                        0
sexo_id                                     0
edad                                        0
maximo_grado_academico_id                   0
disciplina_maximo_grado_academico_id        0
disciplina_titulo_grado_id                  0
disciplina_experticia_id                    0
tipo_personal_id                            0
producciones_ult_anio                       0
producciones_ult_2_anios                    0
producciones_ult_3_anios                    0
producciones_ult_4_anios                    0
institucion_trabajo_id                      0
seniority_level                             0
categoria_conicet_id                    19912
categoria_incentivos                    19912
max_dedicacion_horaria_docente_id       19912
institucion_cargo_docente_id            19912
clase_cargo_docente_id                  19912
tipo_condicion_docente_id               19912
dtype: int64
```
</details>



Podemos hacer esta inspecci√≥n de los datos de forma visual:

```python
import seaborn as sns

sns.heatmap(personas.isnull(), cmap='viridis')
```

![Resultado](./heat_map_null.jpeg)


>
> Para pensar ü§î: ¬øCu√°les son las columnas con valores nulos? ¬øCoinciden con las que ten√≠an valores `NaN`?¬øQu√© obtenemos cu√°ndo hacemos `isnull()`?
>
>  üßó‚Äç‚ôÄÔ∏è Desaf√≠o II: Calcular el porcentaje del total de datos, representan los datos nulos de cada columna (variable)
>

Los datos faltantes pueden alterar el an√°lisis de datos ya que disminuyen el tama√±o de las muestras y, por tanto, la potencia de los tests estad√≠sticos. Por ello, resulta necesario hacer un tratamiento de los datos faltantes, previo al an√°lisis de los datos. Existen distintos modos de trabajar con los datos faltantes, dependiendo mayormente de nuestro lote de datos y de la variable en cuesti√≥n. 

Pero antes de tomar cualquier decisi√≥n, cabe preguntarse algunas cosas: ¬øQu√© informaci√≥n me aporta cada una de las columnas con datos faltantes? ¬øQu√© tipo de datos son los pertenecientas a cada una de las columnas (categ√≥ricos o num√©ricos)?¬øEs relevante dicha variable para el an√°lisis global de los datos? Ser√° entonces, seg√∫n estas respuestas a estas preguntas que decidiremos alguno de los modos de acci√≥n que detallaremos a continuaci√≥n.

Una de las soluciones posibles para el tratamiento de los datos faltantes es la eliminaci√≥n de casos completos, es decir eliminar toda las filas que contienen un dato faltante:

```python
personas.dropna(inplace=True) 
```

O aquellas que tienen m√°s de un dato faltante:

```python
personas.dropna(thresh=2, inplace=True)
```

>
> Para pensar ü§î: ¬øQu√© desventajas crees que tiene esta forma de lidiar con los datos faltantes?¬øCu√°ndo lo usar√≠as?
>

<details>
  <summary>Comentarios</summary>
Esta forma de tratar los faltantes introduce sesgo y reduce el tama√±o muestral. 
</details>

Otra soluci√≥n posible para el tratamiento de datos faltantes ser√≠a la eliminaci√≥n por columna:

```python
personas.drop(['maximo_grado_academico_id'], axis=1, inplace=True)
```

>
> Para pensar ü§î: ¬øQu√© desventajas crees que tiene esta forma de lidiar con los datos faltantes?¬øCu√°ndo lo usar√≠as?
>

<details>
  <summary>Comentarios</summary>
Produce muestras heterog√©neas que no tienem una representaci√≥n clara de las variables
</details>

Una √∫ltima alternativa posible para el manejo de faltantes es estimar los valores ausentes en base a los valores v√°lidos a partir de otros casos de la muestra. Estas estimaciones se pueden hacer, por ejemplo reemplazando los valores faltantes por la media obtenida con los dem√°s valores observados para dicha variable:


```python
df.fillna(df['columna_con_faltantes'].mean(), inplace=True)
```

>
> Para pensar ü§î: ¬øQu√© desventajas crees que tiene esta forma de lidiar con los datos faltantes?¬øCon qu√© criterio? ¬øSiempre puede usarse la media? ¬øQu√© otros valores podr√≠an usarse?
>
>  üßó‚Äç‚ôÄÔ∏è Desaf√≠o III: Escrib√≠ el c√≥digo que usar√≠as para reemplazar los faltantes por la moda y por la mediana.
>
> Para pensar ü§î: ¬øCu√°l son la media, moda y mediana? ¬øY los cuantiles?
>

<details>
  <summary>Comentarios</summary>
Distorsiona la verdadera distribuci√≥n de la variable
Distorsiona la correlaci√≥n entre variables dado que a√±ade valores constantes
</details>

[3. Ajuste de tipos de datos de las columnas y duplicados](#2-tipos_datos)
En algunos casos las bases de datos suelen tener algunas inconsistencias de tipos de datos, por ejemplo columnas que deber√≠an ser num√©ricas y se cargan como (strings) o el formato de las fechas es inadecuado. Es por ello que resulta muy importante cerciorarse antes de operar con las columnas, es necesario realizar algunos ajustes en los tipos de datos.

Podemos conocer el tipo de dato al que se corresponde una columna mediante el m√©todo `dtypes`:

```python
df['columna_de_interes'].dtypes
```

Y convertir una columna a tipo de dato num√©rico, haciendo:

```python
df['columna_de_interes'] = pd.to_numeric(df['columna_de_interes'], errors='coerce')
```

As√≠ mismo es frecuente encontrar celdas duplicadas en los datos, que facilmente pueden ser removidos mediante:

```python
df.drop_duplicates(inplace=True)
```

>  üßó‚Äç‚ôÄÔ∏è Desaf√≠o III: Revis√° el DataFrame para detectar otras anomal√≠as en los datos y averigu√° como resolverlas.
>